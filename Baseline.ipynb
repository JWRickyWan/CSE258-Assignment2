{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import gzip\n",
    "import csv\n",
    "import copy\n",
    "import pickle\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_game_10k_genres.pkl\", \"rb\") as f:\n",
    "    train_rawdata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_game_other1k_genres.pkl\", \"rb\") as f:\n",
    "    valid_rawdata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "    for l in gzip.open(fname,'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamedata =list(parseDataFromFile('./steamData/steam_games.json.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [x[0] for x in train_rawdata]\n",
    "valid_rawdata = [x for x in valid_rawdata if x[0] in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_rawdata+valid_rawdata\n",
    "gameList = set([d[1] for d in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user_game = [[d[0],d[1]] for d in valid_rawdata]\n",
    "train_user_game = [[d[0],d[1]] for d in train_rawdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "userPerGame = defaultdict(set)\n",
    "gamePerUser = defaultdict(set)\n",
    "genrePerUser = defaultdict(set)\n",
    "genrePerGame = defaultdict(set)\n",
    "for data in all_data:\n",
    "    u = data[0]\n",
    "    g = data[1]\n",
    "    gs= data[2]\n",
    "    userPerGame[g].add(u)\n",
    "    gamePerUser[u].add(g)\n",
    "    for genre in gs:\n",
    "        genrePerUser[u].add(genre)\n",
    "        genrePerGame[g].add(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced(d):\n",
    "    balanced = []\n",
    "    for user,game in d:\n",
    "        playedGame = gamePerUser[user]\n",
    "        gameNotPlayed = [k for k in gameList if k not in playedGame]\n",
    "        SampledGame = gameNotPlayed[random.randint(0,len(gameNotPlayed)-1)]\n",
    "        if gameNotPlayed == []:\n",
    "            print(gameNotPlayed)\n",
    "        while([user,SampledGame] in d):\n",
    "            SampledGame = gameNotPlayed[random.randint(0,len(gameNotPlayed)-1)]\n",
    "        balanced.append([user,SampledGame,0])\n",
    "        balanced.append([user,game,1])\n",
    "    return balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_valid = create_balanced(valid_user_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validY = [d[2] for d in balanced_valid ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train = create_balanced(valid_user_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = [d[2] for d in balanced_train ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userGenre(data):\n",
    "    k = []\n",
    "    for user,game,_ in data:\n",
    "        k.append([user,genrePerGame[game]])\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = userGenre(balanced_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = userGenre(balanced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenre(data):\n",
    "    genre2id = {}\n",
    "    id2genre = []\n",
    "    for d in data:\n",
    "        if 'genres' not in d or 'id' not in d: continue\n",
    "        genres = d[\"genres\"]\n",
    "        for genre in genres:\n",
    "            if genre not in id2genre:\n",
    "                genre2id[genre] = len(id2genre)\n",
    "                id2genre.append(genre)\n",
    "    return genre2id,id2genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(x):\n",
    "    feat = [0]*22\n",
    "    for genre in x[1]:\n",
    "        feat[genre2id[genre]]=1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [feature(x) for x in train]\n",
    "valid_X = [feature(x) for x in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre2id,id2genre = getGenre(gamedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate is 0.7248503937007874\n",
      "False Positive Rate is 0.3746771653543307\n",
      "True Negative Rate is 0.6253228346456693\n",
      "False Negative Rate is 0.2751496062992126\n",
      "Accuracy is 0.6750866141732283\n",
      "The Balanced Error is 0.32491338582677165\n",
      "True Positive Rate is 0.7227716535433071\n",
      "False Positive Rate is 0.36976377952755907\n",
      "True Negative Rate is 0.630236220472441\n",
      "False Negative Rate is 0.2772283464566929\n",
      "Accuracy is 0.676503937007874\n",
      "The Balanced Error is 0.32349606299212597\n",
      "True Positive Rate is 0.7148346456692913\n",
      "False Positive Rate is 0.3568503937007874\n",
      "True Negative Rate is 0.6431496062992126\n",
      "False Negative Rate is 0.28516535433070866\n",
      "Accuracy is 0.678992125984252\n",
      "The Balanced Error is 0.32100787401574804\n",
      "True Positive Rate is 0.7148346456692913\n",
      "False Positive Rate is 0.3568503937007874\n",
      "True Negative Rate is 0.6431496062992126\n",
      "False Negative Rate is 0.28516535433070866\n",
      "Accuracy is 0.678992125984252\n",
      "The Balanced Error is 0.32100787401574804\n"
     ]
    }
   ],
   "source": [
    "accus = []\n",
    "for c in [0.01,0.1,1,10]:\n",
    "    model = linear_model.LogisticRegression(C=c,class_weight='balanced',max_iter = 10000000)\n",
    "    model.fit(train_X,trainY)\n",
    "    pred = model.predict(valid_X)\n",
    "    TP_ = np.logical_and(pred, validY)\n",
    "    FP_ = np.logical_and(pred, np.logical_not(validY))\n",
    "    TN_ = np.logical_and(np.logical_not(pred), np.logical_not(validY))\n",
    "    FN_ = np.logical_and(np.logical_not(pred), validY)\n",
    "    TP = sum(TP_)\n",
    "    FP = sum(FP_)\n",
    "    TN = sum(TN_)\n",
    "    FN = sum(FN_)\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    FNR = FN/(TP+FN)\n",
    "    Balanced_Error = 0.5*(FPR+FNR)\n",
    "    accus.append((TP+TN)/(TP+TN+FP+FN))\n",
    "    print(\"True Positive Rate is \"+str(TPR)+\\\n",
    "      \"\\nFalse Positive Rate is \"+str(FPR)+\\\n",
    "      \"\\nTrue Negative Rate is \"+str(TNR)+\\\n",
    "     \"\\nFalse Negative Rate is \"+str(FNR)+\\\n",
    "    \"\\nAccuracy is \"+str((TP+TN)/(TP+TN+FP+FN))+\n",
    "      \"\\nThe Balanced Error is \"+str(Balanced_Error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(x):\n",
    "    feat = [0]*22\n",
    "    for genre in x:\n",
    "        feat[genre2id[genre]]=1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(set([x[0] for x in all_data]))\n",
    "games = list(set([x[1] for x in valid_rawdata]))\n",
    "\n",
    "def mAP_mAR_k(k):\n",
    "    APs = []\n",
    "    ARs = []\n",
    "    for user in users:\n",
    "        preds = [model.predict_proba(np.array(feature(list(genrePerGame[game]))).reshape(1,-1)) for game in games]\n",
    "        # because your linear model has no user input\n",
    "        # so this is actually equavalent to [predict(game) for game in games]\n",
    "        predict = []\n",
    "        for i,game in enumerate(games):\n",
    "            predict.append([preds[i][0][0],preds[i][0][1],game])\n",
    "        predict.sort()\n",
    "        topk = [x[2] for x in predict[:k]]\n",
    "        topk = set(topk)\n",
    "        \n",
    "        ground_truth = gamePerUser[user]\n",
    "        ground_truth = set(ground_truth)\n",
    "        \n",
    "        intersection = topk.intersection(ground_truth)\n",
    "        APs.append(len(intersection) / k)\n",
    "        ARs.append(len(intersection) / len(ground_truth))\n",
    "    \n",
    "    AP = sum(APs) / len(APs)\n",
    "    AR = sum(ARs) / len(ARs)\n",
    "    return AP, AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP3,AR3 = mAP_mAR_k(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015793132211872472, 0.01008826348106289)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP3,AR3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
